{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building CPU and GPU containers for Keras-MXNet on Amazon SageMaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "from sagemaker.amazon.amazon_estimator import get_image_uri\n",
    "container = get_image_uri(boto3.Session().region_name, 'xgboost')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'475088953585.dkr.ecr.ap-southeast-1.amazonaws.com/xgboost:1'"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "sess = sagemaker.Session()\n",
    "role = sagemaker.get_execution_role()\n",
    "account = sess.boto_session.client('sts').get_caller_identity()['Account']\n",
    "region = sess.boto_session.region_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare files required to build the containers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FROM ubuntu:16.04\r\n",
      "\r\n",
      "RUN apt-get update && \\\r\n",
      "    apt-get -y install build-essential libopencv-dev libopenblas-dev libjemalloc-dev libgfortran3 \\\r\n",
      "    python-dev python3-dev python3-pip wget curl\r\n",
      "\r\n",
      "COPY mnist_cnn.py /opt/program/train\r\n",
      "RUN chmod +x /opt/program/train\r\n",
      "\r\n",
      "RUN mkdir /root/.keras\r\n",
      "COPY keras.json /root/.keras/\r\n",
      "\r\n",
      "RUN pip3 install mxnet --upgrade --pre && \\\r\n",
      "    pip3 install keras-mxnet --upgrade --pre\r\n",
      "\r\n",
      "RUN rm -rf /var/lib/apt/lists/*\r\n",
      "RUN rm -rf /root/.cache\r\n",
      "\r\n",
      "ENV PYTHONDONTWRITEBYTECODE=1 \\\r\n",
      "    PYTHONUNBUFFERED=1 \\\r\n",
      "    LD_LIBRARY_PATH=\"${LD_LIBRARY_PATH}:/usr/local/lib\"\r\n",
      "\r\n",
      "ENV PATH=\"/opt/program:${PATH}\"\r\n",
      "\r\n",
      "WORKDIR /opt/program"
     ]
    }
   ],
   "source": [
    "!cat Dockerfile.cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FROM nvidia/cuda:9.0-runtime\r\n",
      "\r\n",
      "RUN apt-get update && \\\r\n",
      "    apt-get -y install build-essential libopencv-dev libopenblas-dev libjemalloc-dev libgfortran3 \\\r\n",
      "    python-dev python3-dev python3-pip wget curl\r\n",
      "\r\n",
      "COPY mnist_cnn.py /opt/program/train\r\n",
      "RUN chmod +x /opt/program/train\r\n",
      "\r\n",
      "RUN mkdir /root/.keras\r\n",
      "COPY keras.json /root/.keras/\r\n",
      "\r\n",
      "RUN pip3 install mxnet-cu90 --upgrade --pre && \\\r\n",
      "    pip3 install keras-mxnet --upgrade --pre\r\n",
      "\r\n",
      "RUN rm -rf /var/lib/apt/lists/*\r\n",
      "RUN rm -rf /root/.cache\r\n",
      "\r\n",
      "ENV PYTHONDONTWRITEBYTECODE=1 \\\r\n",
      "    PYTHONUNBUFFERED=1 \\\r\n",
      "    LD_LIBRARY_PATH=\"${LD_LIBRARY_PATH}:/usr/local/lib\"\r\n",
      "\r\n",
      "ENV PATH=\"/opt/program:${PATH}\"\r\n",
      "\r\n",
      "WORKDIR /opt/program"
     ]
    }
   ],
   "source": [
    "!cat Dockerfile.gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘build’: File exists\r\n"
     ]
    }
   ],
   "source": [
    "mkdir build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy Dockerfiles\n",
    "!cp Dockerfile.* build/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy training script and config file\n",
    "!cp mnist_cnn.py build/\n",
    "!cp keras.json build/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create and login to a repository in ECR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CPU settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: dockerfile=Dockerfile.cpu\n"
     ]
    }
   ],
   "source": [
    "repo_name = 'keras-mxnet-cpu' # ECR repository\n",
    "image_tag = 'keras-mxnet1.2.0-cpu-py3' # ECR image tag\n",
    "base_job_name = 'keras-mxnet-mnist-cnn' # SageMaker training prefix\n",
    "\n",
    "%env dockerfile Dockerfile.cpu\n",
    "\n",
    "train_instance_type='ml.c5.9xlarge'\n",
    "gpu_count=0\n",
    "batch_size=128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPU settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: dockerfile=Dockerfile.gpu\n"
     ]
    }
   ],
   "source": [
    "repo_name = 'keras-mxnet-gpu' # ECR repository\n",
    "image_tag = 'keras-mxnet1.2.0-gpu-py3' # ECR image tag\n",
    "base_job_name = 'keras-mxnet-mnist-cnn' # SageMaker training prefix\n",
    "\n",
    "%env dockerfile Dockerfile.gpu\n",
    "\n",
    "train_instance_type='ml.p3.8xlarge'\n",
    "gpu_count=2\n",
    "batch_size=256"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Common settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: account=349934754982\n",
      "env: region=ap-southeast-1\n",
      "env: repo_name=keras-mxnet-gpu\n",
      "env: image_tag=keras-mxnet1.2.0-gpu-py3\n"
     ]
    }
   ],
   "source": [
    "%env account {account}\n",
    "%env region {region}\n",
    "%env repo_name {repo_name}\n",
    "%env image_tag {image_tag}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create repository and login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Login Succeeded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING! Using --password via the CLI is insecure. Use --password-stdin.\n",
      "WARNING! Your password will be stored unencrypted in /home/ec2-user/.docker/config.json.\n",
      "Configure a credential helper to remove this warning. See\n",
      "https://docs.docker.com/engine/reference/commandline/login/#credentials-store\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "\n",
    "aws ecr describe-repositories --repository-names $repo_name > /dev/null 2>&1\n",
    "if [ $? -ne 0 ]\n",
    "then\n",
    "    aws ecr create-repository --repository-name $repo_name > /dev/null\n",
    "fi\n",
    "\n",
    "$(aws ecr get-login --region $region --no-include-email)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build and tag Docker image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/SageMaker/dlnotebooks/keras/01-custom-container/build\n",
      "Sending build context to Docker daemon  11.78kB\n",
      "Step 1/12 : FROM nvidia/cuda:9.0-runtime\n",
      " ---> ed2bb7e1254e\n",
      "Step 2/12 : RUN apt-get update &&     apt-get -y install build-essential libopencv-dev libopenblas-dev libjemalloc-dev libgfortran3     python-dev python3-dev python3-pip wget curl\n",
      " ---> Using cache\n",
      " ---> 5f62e5baa4e4\n",
      "Step 3/12 : COPY mnist_cnn.py /opt/program/train\n",
      " ---> fc6bd3e6c937\n",
      "Step 4/12 : RUN chmod +x /opt/program/train\n",
      " ---> Running in af0c21b783c4\n",
      "Removing intermediate container af0c21b783c4\n",
      " ---> c7880012620f\n",
      "Step 5/12 : RUN mkdir /root/.keras\n",
      " ---> Running in a4c183cd1b15\n",
      "Removing intermediate container a4c183cd1b15\n",
      " ---> dcdb047a66dc\n",
      "Step 6/12 : COPY keras.json /root/.keras/\n",
      " ---> 58a9aee20ca7\n",
      "Step 7/12 : RUN pip3 install mxnet-cu90 --upgrade --pre &&     pip3 install keras-mxnet --upgrade --pre\n",
      " ---> Running in b3ec029776b7\n",
      "Collecting mxnet-cu90\n",
      "  Downloading https://files.pythonhosted.org/packages/fa/fe/d2c21c7d66dcfcc6807876dc084c2e6f5989564c39d3578c2229a1167902/mxnet_cu90-1.5.0b20190312-py2.py3-none-manylinux1_x86_64.whl (459.6MB)\n",
      "Collecting requests>=2.20.0 (from mxnet-cu90)\n",
      "  Downloading https://files.pythonhosted.org/packages/7d/e3/20f3d364d6c8e5d2353c72a67778eb189176f08e873c9900e10c0287b84b/requests-2.21.0-py2.py3-none-any.whl (57kB)\n",
      "Collecting numpy<1.15.0,>=1.8.2 (from mxnet-cu90)\n",
      "  Downloading https://files.pythonhosted.org/packages/43/f4/ffc029e0ffe001746b288f80e9b2143dafe442a3e87ac1fb9038964d72ab/numpy-1.14.6-cp35-cp35m-manylinux1_x86_64.whl (13.8MB)\n",
      "Collecting graphviz<0.9.0,>=0.8.1 (from mxnet-cu90)\n",
      "  Downloading https://files.pythonhosted.org/packages/53/39/4ab213673844e0c004bed8a0781a0721a3f6bb23eb8854ee75c236428892/graphviz-0.8.4-py2.py3-none-any.whl\n",
      "Collecting urllib3<1.25,>=1.21.1 (from requests>=2.20.0->mxnet-cu90)\n",
      "  Downloading https://files.pythonhosted.org/packages/62/00/ee1d7de624db8ba7090d1226aebefab96a2c71cd5cfa7629d6ad3f61b79e/urllib3-1.24.1-py2.py3-none-any.whl (118kB)\n",
      "Collecting certifi>=2017.4.17 (from requests>=2.20.0->mxnet-cu90)\n",
      "  Downloading https://files.pythonhosted.org/packages/60/75/f692a584e85b7eaba0e03827b3d51f45f571c2e793dd731e598828d380aa/certifi-2019.3.9-py2.py3-none-any.whl (158kB)\n",
      "Collecting chardet<3.1.0,>=3.0.2 (from requests>=2.20.0->mxnet-cu90)\n",
      "  Downloading https://files.pythonhosted.org/packages/bc/a9/01ffebfb562e4274b6487b4bb1ddec7ca55ec7510b22e4c51f14098443b8/chardet-3.0.4-py2.py3-none-any.whl (133kB)\n",
      "Collecting idna<2.9,>=2.5 (from requests>=2.20.0->mxnet-cu90)\n",
      "  Downloading https://files.pythonhosted.org/packages/14/2c/cd551d81dbe15200be1cf41cd03869a46fe7226e7450af7a6545bfc474c9/idna-2.8-py2.py3-none-any.whl (58kB)\n",
      "Installing collected packages: urllib3, certifi, chardet, idna, requests, numpy, graphviz, mxnet-cu90\n",
      "Successfully installed certifi-2019.3.9 chardet-3.0.4 graphviz-0.8.4 idna-2.8 mxnet-cu90-1.5.0b20190312 numpy-1.14.6 requests-2.21.0 urllib3-1.24.1\n",
      "\u001b[91mYou are using pip version 8.1.1, however version 19.0.3 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\n",
      "\u001b[0mCollecting keras-mxnet\n",
      "  Downloading https://files.pythonhosted.org/packages/a1/a9/1fca527a8206327b5603c429607ad431a6ab0f956415532c4051c9ba0381/keras_mxnet-2.2.4.1-py2.py3-none-any.whl (373kB)\n",
      "Collecting keras-applications>=1.0.6 (from keras-mxnet)\n",
      "  Downloading https://files.pythonhosted.org/packages/90/85/64c82949765cfb246bbdaf5aca2d55f400f792655927a017710a78445def/Keras_Applications-1.0.7-py2.py3-none-any.whl (51kB)\n",
      "Collecting keras-preprocessing>=1.0.5 (from keras-mxnet)\n",
      "  Downloading https://files.pythonhosted.org/packages/c0/bf/0315ef6a9fd3fc2346e85b0ff1f5f83ca17073f2c31ac719ab2e4da0d4a3/Keras_Preprocessing-1.0.9-py2.py3-none-any.whl (59kB)\n",
      "Collecting scipy>=0.14 (from keras-mxnet)\n",
      "  Downloading https://files.pythonhosted.org/packages/f0/30/526bee2ce18c066f9ff13ba89603f6c2b96c9fd406b57a21a7ba14bf5679/scipy-1.2.1-cp35-cp35m-manylinux1_x86_64.whl (24.7MB)\n",
      "Collecting h5py (from keras-mxnet)\n",
      "  Downloading https://files.pythonhosted.org/packages/4c/77/c4933e12dca0f61bcdafc207c7532e1250b8d12719459fd85132f3daa9fd/h5py-2.9.0-cp35-cp35m-manylinux1_x86_64.whl (2.8MB)\n",
      "Collecting numpy>=1.9.1 (from keras-mxnet)\n",
      "  Downloading https://files.pythonhosted.org/packages/e3/18/4f013c3c3051f4e0ffbaa4bf247050d6d5e527fe9cb1907f5975b172f23f/numpy-1.16.2-cp35-cp35m-manylinux1_x86_64.whl (17.2MB)\n",
      "Collecting pyyaml (from keras-mxnet)\n",
      "  Downloading https://files.pythonhosted.org/packages/8e/c1/f430175cea36511aeb59a688893d9c4b479c907bebc00d5a022e188ef873/PyYAML-5.1b5.tar.gz (274kB)\n",
      "Collecting six>=1.9.0 (from keras-mxnet)\n",
      "  Downloading https://files.pythonhosted.org/packages/73/fb/00a976f728d0d1fecfe898238ce23f502a721c0ac0ecfedb80e0d88c64e9/six-1.12.0-py2.py3-none-any.whl\n",
      "Building wheels for collected packages: pyyaml\n",
      "  Running setup.py bdist_wheel for pyyaml: started\n",
      "  Running setup.py bdist_wheel for pyyaml: finished with status 'done'\n",
      "  Stored in directory: /root/.cache/pip/wheels/18/60/99/164afc419ba2ea5187e2e7bab16086a73c31d2dfe0d92703fb\n",
      "Successfully built pyyaml\n",
      "Installing collected packages: numpy, six, h5py, keras-applications, keras-preprocessing, scipy, pyyaml, keras-mxnet\n",
      "  Found existing installation: numpy 1.14.6\n",
      "    Uninstalling numpy-1.14.6:\n",
      "      Successfully uninstalled numpy-1.14.6\n",
      "Successfully installed h5py-2.9.0 keras-applications-1.0.7 keras-mxnet-2.2.4.1 keras-preprocessing-1.0.9 numpy-1.16.2 pyyaml-5.1b5 scipy-1.2.1 six-1.12.0\n",
      "\u001b[91mYou are using pip version 8.1.1, however version 19.0.3 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\n",
      "\u001b[0mRemoving intermediate container b3ec029776b7\n",
      " ---> 812da1c4d9f3\n",
      "Step 8/12 : RUN rm -rf /var/lib/apt/lists/*\n",
      " ---> Running in e2f46d3c194e\n",
      "Removing intermediate container e2f46d3c194e\n",
      " ---> 24559761c438\n",
      "Step 9/12 : RUN rm -rf /root/.cache\n",
      " ---> Running in 510cb225e688\n",
      "Removing intermediate container 510cb225e688\n",
      " ---> a53b6a9e1515\n",
      "Step 10/12 : ENV PYTHONDONTWRITEBYTECODE=1     PYTHONUNBUFFERED=1     LD_LIBRARY_PATH=\"${LD_LIBRARY_PATH}:/usr/local/lib\"\n",
      " ---> Running in bc5e3d16b007\n",
      "Removing intermediate container bc5e3d16b007\n",
      " ---> e79422a0f5e5\n",
      "Step 11/12 : ENV PATH=\"/opt/program:${PATH}\"\n",
      " ---> Running in 0652419e6de5\n",
      "Removing intermediate container 0652419e6de5\n",
      " ---> 5d8b7570f44b\n",
      "Step 12/12 : WORKDIR /opt/program\n",
      " ---> Running in 0705bf6e768c\n",
      "Removing intermediate container 0705bf6e768c\n",
      " ---> b8c27305a445\n",
      "Successfully built b8c27305a445\n",
      "Successfully tagged keras-mxnet1.2.0-gpu-py3:latest\n",
      "/home/ec2-user/SageMaker/dlnotebooks/keras/01-custom-container\n"
     ]
    }
   ],
   "source": [
    "%cd build\n",
    "!docker build -t $image_tag -f $dockerfile .\n",
    "%cd ..    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "!docker tag $image_tag $account.dkr.ecr.$region.amazonaws.com/$repo_name:latest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REPOSITORY                                                                       TAG                 IMAGE ID            CREATED             SIZE\r\n",
      "349934754982.dkr.ecr.ap-southeast-1.amazonaws.com/keras-mxnet-gpu                latest              b8c27305a445        1 second ago        3.23GB\r\n",
      "keras-mxnet1.2.0-gpu-py3                                                         latest              b8c27305a445        1 second ago        3.23GB\r\n",
      "349934754982.dkr.ecr.ap-southeast-1.amazonaws.com/keras-mxnet-gpu                <none>              18dd6b65edb0        28 minutes ago      3.23GB\r\n",
      "349934754982.dkr.ecr.ap-southeast-1.amazonaws.com/keras-mxnet-gpu                <none>              227bf52b892d        44 minutes ago      3.23GB\r\n",
      "349934754982.dkr.ecr.ap-southeast-1.amazonaws.com/keras-mxnet-gpu                <none>              e12bbebc012e        About an hour ago   3.23GB\r\n",
      "349934754982.dkr.ecr.ap-southeast-1.amazonaws.com/sagemaker-tf-cifar10-example   latest              0a41375dfc14        3 hours ago         1.56GB\r\n",
      "sagemaker-tf-cifar10-example                                                     latest              0a41375dfc14        3 hours ago         1.56GB\r\n",
      "349934754982.dkr.ecr.ap-southeast-1.amazonaws.com/keras-mxnet-gpu                <none>              9f99ad8598e1        3 hours ago         3.23GB\r\n",
      "nvidia/cuda                                                                      9.0-runtime         ed2bb7e1254e        5 days ago          902MB\r\n",
      "tensorflow/tensorflow                                                            1.8.0-py3           a83a3dd79ff9        10 months ago       1.33GB\r\n"
     ]
    }
   ],
   "source": [
    "!docker images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It's probably a good idea to inspect your container before pushing it :)\n",
    "# !docker -it /bin/bash $CONTAINER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Push Docker image to ECR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The push refers to repository [349934754982.dkr.ecr.ap-southeast-1.amazonaws.com/keras-mxnet-gpu]\n",
      "\n",
      "\u001b[1Ba5a44257: Preparing \n",
      "\u001b[1B935a6123: Preparing \n",
      "\u001b[1Bdf01a092: Preparing \n",
      "\u001b[1Beaca2436: Preparing \n",
      "\u001b[1Bb67622ce: Preparing \n",
      "\u001b[1B8ff508f2: Preparing \n",
      "\u001b[1B05ec5dbd: Preparing \n",
      "\u001b[1B2669ceef: Preparing \n",
      "\u001b[1B49db96b8: Preparing \n",
      "\u001b[1B6bc0e30f: Preparing \n",
      "\u001b[1B7f750489: Preparing \n",
      "\u001b[1Beddd58ba: Preparing \n",
      "\u001b[1Ba0c9a8cd: Preparing \n",
      "\u001b[1B91ae09b8: Preparing \n",
      "\u001b[1B8b4c3da7: Preparing \n",
      "\u001b[14Bf01a092: Pushed   1.439GB/1.435GB\u001b[16A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[13A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[11A\u001b[1K\u001b[K\u001b[9A\u001b[1K\u001b[K\u001b[8A\u001b[1K\u001b[K\u001b[5A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[2A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[11A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[10A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[Klatest: digest: sha256:d4d3df0a16c234f790d41f484305ff1595cda000fca9eca853f5df5f54fbe797 size: 3663\n"
     ]
    }
   ],
   "source": [
    "!docker push $account.dkr.ecr.$region.amazonaws.com/$repo_name:latest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload MNIST data to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_directory = 'data'\n",
    "prefix          = repo_name+'/input'\n",
    "\n",
    "train_input_path      = sess.upload_data(local_directory+'/train/',      key_prefix=prefix+'/train')\n",
    "validation_input_path = sess.upload_data(local_directory+'/validation/', key_prefix=prefix+'/validation')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train with the custom container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: keras-mxnet-mnist-cnn-2019-03-13-00-39-33-681\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sagemaker-ap-southeast-1-349934754982/keras-mxnet-gpu/output\n",
      "349934754982.dkr.ecr.ap-southeast-1.amazonaws.com/keras-mxnet-gpu:latest\n",
      "2019-03-13 00:39:33 Starting - Starting the training job...\n",
      "2019-03-13 00:39:35 Starting - Launching requested ML instances.........\n",
      "2019-03-13 00:41:07 Starting - Preparing the instances for training...\n",
      "2019-03-13 00:42:01 Downloading - Downloading input data...\n",
      "2019-03-13 00:42:08 Training - Downloading the training image...\n",
      "2019-03-13 00:43:02 Training - Training image download completed. Training in progress..\n",
      "\u001b[31mUsing MXNet backend\u001b[0m\n",
      "\u001b[31mHyper parameters: {'batch_size': '256', 'gpus': '2', 'epochs': '10', 'lr': '0.01'}\u001b[0m\n",
      "\u001b[31mInput parameters: {'validation': {'TrainingInputMode': 'File', 'RecordWrapperType': 'None', 'S3DistributionType': 'FullyReplicated'}, 'training': {'TrainingInputMode': 'File', 'RecordWrapperType': 'None', 'S3DistributionType': 'FullyReplicated'}}\u001b[0m\n",
      "\u001b[31mFiles loaded\u001b[0m\n",
      "\u001b[31mx_train shape: (60000, 1, 28, 28)\u001b[0m\n",
      "\u001b[31m60000 train samples\u001b[0m\n",
      "\u001b[31m10000 test samples\u001b[0m\n",
      "\u001b[31mTrain on 60000 samples, validate on 10000 samples\u001b[0m\n",
      "\u001b[31mEpoch 1/10\u001b[0m\n",
      "\u001b[31m/usr/local/lib/python3.5/dist-packages/mxnet/module/bucketing_module.py:411: UserWarning: Optimizer created manually outside Module but rescale_grad is not normalized to 1.0/batch_size/num_workers (1.0 vs. 0.00390625). Is this intended?\n",
      "  force_init=force_init)\u001b[0m\n",
      "\u001b[31m[00:43:13] src/operator/nn/./cudnn/./cudnn_algoreg-inl.h:97: Running performance tests to find the best convolution algorithm, this can take a while... (setting env variable MXNET_CUDNN_AUTOTUNE_DEFAULT to 0 to disable)\u001b[0m\n",
      "\u001b[31m  256/60000 [..............................] - ETA: 33:46 - loss: 2.2992 - acc: 0.0742\n",
      " 2304/60000 [>.............................] - ETA: 3:38 - loss: 1.7790 - acc: 0.4557 \n",
      " 5120/60000 [=>............................] - ETA: 1:34 - loss: 1.2747 - acc: 0.6039\n",
      " 7936/60000 [==>...........................] - ETA: 57s - loss: 1.0248 - acc: 0.6816 \u001b[0m\n",
      "\u001b[31m10752/60000 [====>.........................] - ETA: 40s - loss: 0.8777 - acc: 0.7279\u001b[0m\n",
      "\u001b[31m13568/60000 [=====>........................] - ETA: 30s - loss: 0.7771 - acc: 0.7588\u001b[0m\n",
      "\u001b[31m16384/60000 [=======>......................] - ETA: 23s - loss: 0.7026 - acc: 0.7828\u001b[0m\n",
      "\u001b[31m19200/60000 [========>.....................] - ETA: 19s - loss: 0.6437 - acc: 0.8015\u001b[0m\n",
      "\u001b[31m22016/60000 [==========>...................] - ETA: 15s - loss: 0.5954 - acc: 0.8173\u001b[0m\n",
      "\u001b[31m24832/60000 [===========>..................] - ETA: 12s - loss: 0.5549 - acc: 0.8298\u001b[0m\n",
      "\u001b[31m27648/60000 [============>.................] - ETA: 10s - loss: 0.5233 - acc: 0.8396\u001b[0m\n",
      "\u001b[31m30464/60000 [==============>...............] - ETA: 8s - loss: 0.4942 - acc: 0.8488 \u001b[0m\n",
      "\u001b[31m33280/60000 [===============>..............] - ETA: 7s - loss: 0.4680 - acc: 0.8570\u001b[0m\n",
      "\u001b[31m36096/60000 [=================>............] - ETA: 6s - loss: 0.4458 - acc: 0.8637\u001b[0m\n",
      "\u001b[31m38912/60000 [==================>...........] - ETA: 5s - loss: 0.4262 - acc: 0.8695\u001b[0m\n",
      "\u001b[31m41728/60000 [===================>..........] - ETA: 4s - loss: 0.4092 - acc: 0.8748\u001b[0m\n",
      "\u001b[31m44544/60000 [=====================>........] - ETA: 3s - loss: 0.3959 - acc: 0.8793\u001b[0m\n",
      "\u001b[31m47360/60000 [======================>.......] - ETA: 2s - loss: 0.3816 - acc: 0.8839\u001b[0m\n",
      "\u001b[31m50176/60000 [========================>.....] - ETA: 1s - loss: 0.3693 - acc: 0.8877\u001b[0m\n",
      "\u001b[31m52736/60000 [=========================>....] - ETA: 1s - loss: 0.3595 - acc: 0.8908\u001b[0m\n",
      "\u001b[31m55552/60000 [==========================>...] - ETA: 0s - loss: 0.3481 - acc: 0.8943\u001b[0m\n",
      "\u001b[31m58368/60000 [============================>.] - ETA: 0s - loss: 0.3379 - acc: 0.8975\u001b[0m\n",
      "\u001b[31m60000/60000 [==============================] - 10s 167us/step - loss: 0.3327 - acc: 0.8992 - val_loss: 0.0674 - val_acc: 0.9787\u001b[0m\n",
      "\u001b[31mEpoch 2/10\n",
      "\n",
      "  256/60000 [..............................] - ETA: 1s - loss: 0.1372 - acc: 0.9688\n",
      " 3072/60000 [>.............................] - ETA: 1s - loss: 0.1346 - acc: 0.9655\n",
      " 5888/60000 [=>............................] - ETA: 1s - loss: 0.1263 - acc: 0.9662\n",
      " 8704/60000 [===>..........................] - ETA: 0s - loss: 0.1224 - acc: 0.9653\u001b[0m\n",
      "\u001b[31m11520/60000 [====>.........................] - ETA: 0s - loss: 0.1215 - acc: 0.9661\u001b[0m\n",
      "\u001b[31m14336/60000 [======>.......................] - ETA: 0s - loss: 0.1176 - acc: 0.9669\u001b[0m\n",
      "\u001b[31m17152/60000 [=======>......................] - ETA: 0s - loss: 0.1186 - acc: 0.9665\u001b[0m\n",
      "\u001b[31m19968/60000 [========>.....................] - ETA: 0s - loss: 0.1177 - acc: 0.9663\u001b[0m\n",
      "\u001b[31m22784/60000 [==========>...................] - ETA: 0s - loss: 0.1161 - acc: 0.9668\u001b[0m\n",
      "\u001b[31m25600/60000 [===========>..................] - ETA: 0s - loss: 0.1153 - acc: 0.9668\u001b[0m\n",
      "\u001b[31m28416/60000 [=============>................] - ETA: 0s - loss: 0.1124 - acc: 0.9679\u001b[0m\n",
      "\u001b[31m31232/60000 [==============>...............] - ETA: 0s - loss: 0.1136 - acc: 0.9673\u001b[0m\n",
      "\u001b[31m34048/60000 [================>.............] - ETA: 0s - loss: 0.1120 - acc: 0.9676\u001b[0m\n",
      "\u001b[31m36864/60000 [=================>............] - ETA: 0s - loss: 0.1105 - acc: 0.9681\u001b[0m\n",
      "\u001b[31m39680/60000 [==================>...........] - ETA: 0s - loss: 0.1099 - acc: 0.9684\u001b[0m\n",
      "\u001b[31m42496/60000 [====================>.........] - ETA: 0s - loss: 0.1091 - acc: 0.9684\u001b[0m\n",
      "\u001b[31m45312/60000 [=====================>........] - ETA: 0s - loss: 0.1079 - acc: 0.9688\u001b[0m\n",
      "\u001b[31m48128/60000 [=======================>......] - ETA: 0s - loss: 0.1087 - acc: 0.9687\u001b[0m\n",
      "\u001b[31m50944/60000 [========================>.....] - ETA: 0s - loss: 0.1077 - acc: 0.9689\u001b[0m\n",
      "\u001b[31m53760/60000 [=========================>....] - ETA: 0s - loss: 0.1072 - acc: 0.9691\u001b[0m\n",
      "\u001b[31m56576/60000 [===========================>..] - ETA: 0s - loss: 0.1061 - acc: 0.9695\u001b[0m\n",
      "\u001b[31m59392/60000 [============================>.] - ETA: 0s - loss: 0.1054 - acc: 0.9697\u001b[0m\n",
      "\u001b[31m60000/60000 [==============================] - 1s 20us/step - loss: 0.1053 - acc: 0.9698 - val_loss: 0.0451 - val_acc: 0.9858\u001b[0m\n",
      "\u001b[31mEpoch 3/10\n",
      "\n",
      "  256/60000 [..............................] - ETA: 1s - loss: 0.0793 - acc: 0.9766\n",
      " 3072/60000 [>.............................] - ETA: 1s - loss: 0.0800 - acc: 0.9753\n",
      " 5888/60000 [=>............................] - ETA: 1s - loss: 0.0761 - acc: 0.9766\n",
      " 8704/60000 [===>..........................] - ETA: 0s - loss: 0.0792 - acc: 0.9745\u001b[0m\n",
      "\u001b[31m11520/60000 [====>.........................] - ETA: 0s - loss: 0.0762 - acc: 0.9754\u001b[0m\n",
      "\u001b[31m14336/60000 [======>.......................] - ETA: 0s - loss: 0.0743 - acc: 0.9764\u001b[0m\n",
      "\u001b[31m17152/60000 [=======>......................] - ETA: 0s - loss: 0.0751 - acc: 0.9764\u001b[0m\n",
      "\u001b[31m19968/60000 [========>.....................] - ETA: 0s - loss: 0.0755 - acc: 0.9768\u001b[0m\n",
      "\u001b[31m22784/60000 [==========>...................] - ETA: 0s - loss: 0.0747 - acc: 0.9773\u001b[0m\n",
      "\u001b[31m25600/60000 [===========>..................] - ETA: 0s - loss: 0.0759 - acc: 0.9770\u001b[0m\n",
      "\u001b[31m28416/60000 [=============>................] - ETA: 0s - loss: 0.0764 - acc: 0.9770\u001b[0m\n",
      "\u001b[31m31232/60000 [==============>...............] - ETA: 0s - loss: 0.0759 - acc: 0.9770\u001b[0m\n",
      "\u001b[31m34048/60000 [================>.............] - ETA: 0s - loss: 0.0765 - acc: 0.9769\u001b[0m\n",
      "\u001b[31m36864/60000 [=================>............] - ETA: 0s - loss: 0.0775 - acc: 0.9767\u001b[0m\n",
      "\u001b[31m39680/60000 [==================>...........] - ETA: 0s - loss: 0.0770 - acc: 0.9768\u001b[0m\n",
      "\u001b[31m42496/60000 [====================>.........] - ETA: 0s - loss: 0.0771 - acc: 0.9767\u001b[0m\n",
      "\u001b[31m45312/60000 [=====================>........] - ETA: 0s - loss: 0.0775 - acc: 0.9764\u001b[0m\n",
      "\u001b[31m48128/60000 [=======================>......] - ETA: 0s - loss: 0.0783 - acc: 0.9764\u001b[0m\n",
      "\u001b[31m50944/60000 [========================>.....] - ETA: 0s - loss: 0.0777 - acc: 0.9765\u001b[0m\n",
      "\u001b[31m53760/60000 [=========================>....] - ETA: 0s - loss: 0.0776 - acc: 0.9766\u001b[0m\n",
      "\u001b[31m56576/60000 [===========================>..] - ETA: 0s - loss: 0.0775 - acc: 0.9766\u001b[0m\n",
      "\u001b[31m59392/60000 [============================>.] - ETA: 0s - loss: 0.0776 - acc: 0.9767\u001b[0m\n",
      "\u001b[31m60000/60000 [==============================] - 1s 20us/step - loss: 0.0778 - acc: 0.9766 - val_loss: 0.0373 - val_acc: 0.9877\u001b[0m\n",
      "\u001b[31mEpoch 4/10\n",
      "\n",
      "  256/60000 [..............................] - ETA: 1s - loss: 0.1120 - acc: 0.9805\n",
      " 3072/60000 [>.............................] - ETA: 1s - loss: 0.0696 - acc: 0.9805\n",
      " 5888/60000 [=>............................] - ETA: 1s - loss: 0.0646 - acc: 0.9828\u001b[0m\n",
      "\u001b[31m 8704/60000 [===>..........................] - ETA: 0s - loss: 0.0619 - acc: 0.9831\u001b[0m\n",
      "\u001b[31m11520/60000 [====>.........................] - ETA: 0s - loss: 0.0602 - acc: 0.9833\u001b[0m\n",
      "\u001b[31m14080/60000 [======>.......................] - ETA: 0s - loss: 0.0619 - acc: 0.9825\u001b[0m\n",
      "\u001b[31m16640/60000 [=======>......................] - ETA: 0s - loss: 0.0635 - acc: 0.9816\u001b[0m\n",
      "\u001b[31m19456/60000 [========>.....................] - ETA: 0s - loss: 0.0624 - acc: 0.9816\u001b[0m\n",
      "\u001b[31m22272/60000 [==========>...................] - ETA: 0s - loss: 0.0623 - acc: 0.9815\u001b[0m\n",
      "\u001b[31m25088/60000 [===========>..................] - ETA: 0s - loss: 0.0628 - acc: 0.9818\u001b[0m\n",
      "\u001b[31m27904/60000 [============>.................] - ETA: 0s - loss: 0.0630 - acc: 0.9818\u001b[0m\n",
      "\u001b[31m30720/60000 [==============>...............] - ETA: 0s - loss: 0.0619 - acc: 0.9820\u001b[0m\n",
      "\u001b[31m33536/60000 [===============>..............] - ETA: 0s - loss: 0.0613 - acc: 0.9820\u001b[0m\n",
      "\u001b[31m36352/60000 [=================>............] - ETA: 0s - loss: 0.0615 - acc: 0.9818\u001b[0m\n",
      "\u001b[31m39168/60000 [==================>...........] - ETA: 0s - loss: 0.0615 - acc: 0.9818\u001b[0m\n",
      "\u001b[31m41984/60000 [===================>..........] - ETA: 0s - loss: 0.0620 - acc: 0.9816\u001b[0m\n",
      "\u001b[31m44800/60000 [=====================>........] - ETA: 0s - loss: 0.0620 - acc: 0.9816\u001b[0m\n",
      "\u001b[31m47616/60000 [======================>.......] - ETA: 0s - loss: 0.0619 - acc: 0.9818\u001b[0m\n",
      "\u001b[31m50432/60000 [========================>.....] - ETA: 0s - loss: 0.0614 - acc: 0.9820\u001b[0m\n",
      "\u001b[31m53248/60000 [=========================>....] - ETA: 0s - loss: 0.0611 - acc: 0.9822\u001b[0m\n",
      "\u001b[31m56064/60000 [===========================>..] - ETA: 0s - loss: 0.0610 - acc: 0.9823\u001b[0m\n",
      "\u001b[31m58880/60000 [============================>.] - ETA: 0s - loss: 0.0619 - acc: 0.9820\u001b[0m\n",
      "\u001b[31m60000/60000 [==============================] - 1s 21us/step - loss: 0.0621 - acc: 0.9818 - val_loss: 0.0333 - val_acc: 0.9894\u001b[0m\n",
      "\u001b[31mEpoch 5/10\n",
      "\n",
      "  256/60000 [..............................] - ETA: 1s - loss: 0.0907 - acc: 0.9688\n",
      " 3072/60000 [>.............................] - ETA: 1s - loss: 0.0633 - acc: 0.9785\n",
      " 5888/60000 [=>............................] - ETA: 1s - loss: 0.0592 - acc: 0.9813\n",
      " 8704/60000 [===>..........................] - ETA: 0s - loss: 0.0574 - acc: 0.9818\u001b[0m\n",
      "\u001b[31m11520/60000 [====>.........................] - ETA: 0s - loss: 0.0579 - acc: 0.9823\u001b[0m\n",
      "\u001b[31m14336/60000 [======>.......................] - ETA: 0s - loss: 0.0574 - acc: 0.9822\u001b[0m\n",
      "\u001b[31m17152/60000 [=======>......................] - ETA: 0s - loss: 0.0562 - acc: 0.9828\u001b[0m\n",
      "\u001b[31m19968/60000 [========>.....................] - ETA: 0s - loss: 0.0566 - acc: 0.9828\u001b[0m\n",
      "\u001b[31m22784/60000 [==========>...................] - ETA: 0s - loss: 0.0563 - acc: 0.9827\u001b[0m\n",
      "\u001b[31m25600/60000 [===========>..................] - ETA: 0s - loss: 0.0561 - acc: 0.9826\u001b[0m\n",
      "\u001b[31m28416/60000 [=============>................] - ETA: 0s - loss: 0.0548 - acc: 0.9829\u001b[0m\n",
      "\u001b[31m31232/60000 [==============>...............] - ETA: 0s - loss: 0.0555 - acc: 0.9828\u001b[0m\n",
      "\u001b[31m34048/60000 [================>.............] - ETA: 0s - loss: 0.0547 - acc: 0.9831\u001b[0m\n",
      "\u001b[31m36864/60000 [=================>............] - ETA: 0s - loss: 0.0541 - acc: 0.9832\u001b[0m\n",
      "\u001b[31m39680/60000 [==================>...........] - ETA: 0s - loss: 0.0542 - acc: 0.9833\u001b[0m\n",
      "\u001b[31m42496/60000 [====================>.........] - ETA: 0s - loss: 0.0535 - acc: 0.9833\u001b[0m\n",
      "\u001b[31m45312/60000 [=====================>........] - ETA: 0s - loss: 0.0542 - acc: 0.9831\u001b[0m\n",
      "\u001b[31m48128/60000 [=======================>......] - ETA: 0s - loss: 0.0540 - acc: 0.9831\u001b[0m\n",
      "\u001b[31m50944/60000 [========================>.....] - ETA: 0s - loss: 0.0538 - acc: 0.9832\u001b[0m\n",
      "\u001b[31m53760/60000 [=========================>....] - ETA: 0s - loss: 0.0534 - acc: 0.9834\u001b[0m\n",
      "\u001b[31m56576/60000 [===========================>..] - ETA: 0s - loss: 0.0534 - acc: 0.9835\u001b[0m\n",
      "\u001b[31m59392/60000 [============================>.] - ETA: 0s - loss: 0.0530 - acc: 0.9837\u001b[0m\n",
      "\u001b[31m60000/60000 [==============================] - 1s 20us/step - loss: 0.0531 - acc: 0.9836 - val_loss: 0.0300 - val_acc: 0.9900\u001b[0m\n",
      "\u001b[31mEpoch 6/10\n",
      "\n",
      "  256/60000 [..............................] - ETA: 1s - loss: 0.0261 - acc: 0.9961\n",
      " 3072/60000 [>.............................] - ETA: 1s - loss: 0.0435 - acc: 0.9883\n",
      " 5888/60000 [=>............................] - ETA: 1s - loss: 0.0446 - acc: 0.9862\n",
      " 8704/60000 [===>..........................] - ETA: 0s - loss: 0.0440 - acc: 0.9859\u001b[0m\n",
      "\u001b[31m11520/60000 [====>.........................] - ETA: 0s - loss: 0.0447 - acc: 0.9857\u001b[0m\n",
      "\u001b[31m14336/60000 [======>.......................] - ETA: 0s - loss: 0.0427 - acc: 0.9865\u001b[0m\n",
      "\u001b[31m17152/60000 [=======>......................] - ETA: 0s - loss: 0.0434 - acc: 0.9864\u001b[0m\n",
      "\u001b[31m19968/60000 [========>.....................] - ETA: 0s - loss: 0.0433 - acc: 0.9862\u001b[0m\n",
      "\u001b[31m22784/60000 [==========>...................] - ETA: 0s - loss: 0.0441 - acc: 0.9858\u001b[0m\n",
      "\u001b[31m25600/60000 [===========>..................] - ETA: 0s - loss: 0.0437 - acc: 0.9859\u001b[0m\n",
      "\u001b[31m28416/60000 [=============>................] - ETA: 0s - loss: 0.0444 - acc: 0.9856\u001b[0m\n",
      "\u001b[31m31232/60000 [==============>...............] - ETA: 0s - loss: 0.0450 - acc: 0.9856\u001b[0m\n",
      "\u001b[31m34048/60000 [================>.............] - ETA: 0s - loss: 0.0450 - acc: 0.9859\u001b[0m\n",
      "\u001b[31m36864/60000 [=================>............] - ETA: 0s - loss: 0.0456 - acc: 0.9855\u001b[0m\n",
      "\u001b[31m39680/60000 [==================>...........] - ETA: 0s - loss: 0.0454 - acc: 0.9856\u001b[0m\n",
      "\u001b[31m42496/60000 [====================>.........] - ETA: 0s - loss: 0.0455 - acc: 0.9854\u001b[0m\n",
      "\u001b[31m45312/60000 [=====================>........] - ETA: 0s - loss: 0.0460 - acc: 0.9853\u001b[0m\n",
      "\u001b[31m48128/60000 [=======================>......] - ETA: 0s - loss: 0.0458 - acc: 0.9855\u001b[0m\n",
      "\u001b[31m50944/60000 [========================>.....] - ETA: 0s - loss: 0.0457 - acc: 0.9856\u001b[0m\n",
      "\u001b[31m53760/60000 [=========================>....] - ETA: 0s - loss: 0.0455 - acc: 0.9856\u001b[0m\n",
      "\u001b[31m56576/60000 [===========================>..] - ETA: 0s - loss: 0.0456 - acc: 0.9856\u001b[0m\n",
      "\u001b[31m59392/60000 [============================>.] - ETA: 0s - loss: 0.0457 - acc: 0.9854\u001b[0m\n",
      "\u001b[31m60000/60000 [==============================] - 1s 21us/step - loss: 0.0456 - acc: 0.9855 - val_loss: 0.0284 - val_acc: 0.9898\u001b[0m\n",
      "\u001b[31mEpoch 7/10\n",
      "\n",
      "  256/60000 [..............................] - ETA: 1s - loss: 0.0464 - acc: 0.9883\n",
      " 3072/60000 [>.............................] - ETA: 1s - loss: 0.0271 - acc: 0.9925\n",
      " 5888/60000 [=>............................] - ETA: 1s - loss: 0.0327 - acc: 0.9908\n",
      " 8704/60000 [===>..........................] - ETA: 0s - loss: 0.0345 - acc: 0.9903\u001b[0m\n",
      "\u001b[31m11520/60000 [====>.........................] - ETA: 0s - loss: 0.0369 - acc: 0.9894\u001b[0m\n",
      "\u001b[31m14336/60000 [======>.......................] - ETA: 0s - loss: 0.0387 - acc: 0.9885\u001b[0m\n",
      "\u001b[31m17152/60000 [=======>......................] - ETA: 0s - loss: 0.0394 - acc: 0.9887\u001b[0m\n",
      "\u001b[31m19968/60000 [========>.....................] - ETA: 0s - loss: 0.0403 - acc: 0.9883\u001b[0m\n",
      "\u001b[31m22784/60000 [==========>...................] - ETA: 0s - loss: 0.0421 - acc: 0.9878\u001b[0m\n",
      "\u001b[31m25600/60000 [===========>..................] - ETA: 0s - loss: 0.0413 - acc: 0.9880\u001b[0m\n",
      "\u001b[31m28416/60000 [=============>................] - ETA: 0s - loss: 0.0411 - acc: 0.9881\u001b[0m\n",
      "\u001b[31m31232/60000 [==============>...............] - ETA: 0s - loss: 0.0411 - acc: 0.9879\u001b[0m\n",
      "\u001b[31m34048/60000 [================>.............] - ETA: 0s - loss: 0.0412 - acc: 0.9878\u001b[0m\n",
      "\u001b[31m36864/60000 [=================>............] - ETA: 0s - loss: 0.0406 - acc: 0.9879\u001b[0m\n",
      "\u001b[31m39680/60000 [==================>...........] - ETA: 0s - loss: 0.0404 - acc: 0.9878\u001b[0m\n",
      "\u001b[31m42496/60000 [====================>.........] - ETA: 0s - loss: 0.0404 - acc: 0.9878\u001b[0m\n",
      "\u001b[31m45312/60000 [=====================>........] - ETA: 0s - loss: 0.0402 - acc: 0.9879\u001b[0m\n",
      "\u001b[31m48128/60000 [=======================>......] - ETA: 0s - loss: 0.0399 - acc: 0.9879\u001b[0m\n",
      "\u001b[31m50944/60000 [========================>.....] - ETA: 0s - loss: 0.0396 - acc: 0.9880\u001b[0m\n",
      "\u001b[31m53760/60000 [=========================>....] - ETA: 0s - loss: 0.0393 - acc: 0.9881\u001b[0m\n",
      "\u001b[31m56576/60000 [===========================>..] - ETA: 0s - loss: 0.0394 - acc: 0.9880\u001b[0m\n",
      "\u001b[31m59392/60000 [============================>.] - ETA: 0s - loss: 0.0392 - acc: 0.9881\u001b[0m\n",
      "\u001b[31m60000/60000 [==============================] - 1s 20us/step - loss: 0.0393 - acc: 0.9881 - val_loss: 0.0310 - val_acc: 0.9904\u001b[0m\n",
      "\u001b[31mEpoch 8/10\n",
      "\n",
      "  256/60000 [..............................] - ETA: 1s - loss: 0.0303 - acc: 0.9883\n",
      " 3072/60000 [>.............................] - ETA: 1s - loss: 0.0336 - acc: 0.9886\n",
      " 5888/60000 [=>............................] - ETA: 1s - loss: 0.0367 - acc: 0.9864\n",
      " 8704/60000 [===>..........................] - ETA: 0s - loss: 0.0366 - acc: 0.9869\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2019-03-13 00:43:34 Uploading - Uploading generated training model\n",
      "2019-03-13 00:43:34 Completed - Training job completed\n",
      "\u001b[31m11520/60000 [====>.........................] - ETA: 0s - loss: 0.0367 - acc: 0.9874\u001b[0m\n",
      "\u001b[31m14336/60000 [======>.......................] - ETA: 0s - loss: 0.0389 - acc: 0.9870\u001b[0m\n",
      "\u001b[31m17152/60000 [=======>......................] - ETA: 0s - loss: 0.0374 - acc: 0.9877\u001b[0m\n",
      "\u001b[31m19968/60000 [========>.....................] - ETA: 0s - loss: 0.0376 - acc: 0.9879\u001b[0m\n",
      "\u001b[31m22784/60000 [==========>...................] - ETA: 0s - loss: 0.0372 - acc: 0.9880\u001b[0m\n",
      "\u001b[31m25600/60000 [===========>..................] - ETA: 0s - loss: 0.0365 - acc: 0.9881\u001b[0m\n",
      "\u001b[31m28416/60000 [=============>................] - ETA: 0s - loss: 0.0369 - acc: 0.9878\u001b[0m\n",
      "\u001b[31m31232/60000 [==============>...............] - ETA: 0s - loss: 0.0373 - acc: 0.9877\u001b[0m\n",
      "\u001b[31m34048/60000 [================>.............] - ETA: 0s - loss: 0.0362 - acc: 0.9880\u001b[0m\n",
      "\u001b[31m36864/60000 [=================>............] - ETA: 0s - loss: 0.0363 - acc: 0.9880\u001b[0m\n",
      "\u001b[31m39680/60000 [==================>...........] - ETA: 0s - loss: 0.0355 - acc: 0.9883\u001b[0m\n",
      "\u001b[31m42496/60000 [====================>.........] - ETA: 0s - loss: 0.0363 - acc: 0.9881\u001b[0m\n",
      "\u001b[31m45312/60000 [=====================>........] - ETA: 0s - loss: 0.0368 - acc: 0.9882\u001b[0m\n",
      "\u001b[31m48128/60000 [=======================>......] - ETA: 0s - loss: 0.0374 - acc: 0.9880\u001b[0m\n",
      "\u001b[31m50944/60000 [========================>.....] - ETA: 0s - loss: 0.0375 - acc: 0.9879\u001b[0m\n",
      "\u001b[31m53760/60000 [=========================>....] - ETA: 0s - loss: 0.0374 - acc: 0.9880\u001b[0m\n",
      "\u001b[31m56576/60000 [===========================>..] - ETA: 0s - loss: 0.0377 - acc: 0.9879\u001b[0m\n",
      "\u001b[31m59392/60000 [============================>.] - ETA: 0s - loss: 0.0376 - acc: 0.9880\u001b[0m\n",
      "\u001b[31m60000/60000 [==============================] - 1s 21us/step - loss: 0.0377 - acc: 0.9879 - val_loss: 0.0301 - val_acc: 0.9910\u001b[0m\n",
      "\u001b[31mEpoch 9/10\n",
      "\u001b[0m\n",
      "\u001b[31m  256/60000 [..............................] - ETA: 1s - loss: 0.0174 - acc: 1.0000\n",
      " 3072/60000 [>.............................] - ETA: 1s - loss: 0.0386 - acc: 0.9860\n",
      " 5888/60000 [=>............................] - ETA: 1s - loss: 0.0338 - acc: 0.9886\n",
      " 8704/60000 [===>..........................] - ETA: 0s - loss: 0.0327 - acc: 0.9889\u001b[0m\n",
      "\u001b[31m11520/60000 [====>.........................] - ETA: 0s - loss: 0.0323 - acc: 0.9891\u001b[0m\n",
      "\u001b[31m14336/60000 [======>.......................] - ETA: 0s - loss: 0.0336 - acc: 0.9893\u001b[0m\n",
      "\u001b[31m17152/60000 [=======>......................] - ETA: 0s - loss: 0.0325 - acc: 0.9898\u001b[0m\n",
      "\u001b[31m19968/60000 [========>.....................] - ETA: 0s - loss: 0.0330 - acc: 0.9896\u001b[0m\n",
      "\u001b[31m22784/60000 [==========>...................] - ETA: 0s - loss: 0.0320 - acc: 0.9898\u001b[0m\n",
      "\u001b[31m25600/60000 [===========>..................] - ETA: 0s - loss: 0.0317 - acc: 0.9897\u001b[0m\n",
      "\u001b[31m28416/60000 [=============>................] - ETA: 0s - loss: 0.0315 - acc: 0.9898\u001b[0m\n",
      "\u001b[31m31232/60000 [==============>...............] - ETA: 0s - loss: 0.0311 - acc: 0.9899\u001b[0m\n",
      "\u001b[31m34048/60000 [================>.............] - ETA: 0s - loss: 0.0316 - acc: 0.9898\u001b[0m\n",
      "\u001b[31m36864/60000 [=================>............] - ETA: 0s - loss: 0.0321 - acc: 0.9898\u001b[0m\n",
      "\u001b[31m39680/60000 [==================>...........] - ETA: 0s - loss: 0.0323 - acc: 0.9897\u001b[0m\n",
      "\u001b[31m42496/60000 [====================>.........] - ETA: 0s - loss: 0.0324 - acc: 0.9897\u001b[0m\n",
      "\u001b[31m45312/60000 [=====================>........] - ETA: 0s - loss: 0.0325 - acc: 0.9897\u001b[0m\n",
      "\u001b[31m48128/60000 [=======================>......] - ETA: 0s - loss: 0.0330 - acc: 0.9896\u001b[0m\n",
      "\u001b[31m50944/60000 [========================>.....] - ETA: 0s - loss: 0.0331 - acc: 0.9895\u001b[0m\n",
      "\u001b[31m53760/60000 [=========================>....] - ETA: 0s - loss: 0.0336 - acc: 0.9893\u001b[0m\n",
      "\u001b[31m56576/60000 [===========================>..] - ETA: 0s - loss: 0.0336 - acc: 0.9894\u001b[0m\n",
      "\u001b[31m59392/60000 [============================>.] - ETA: 0s - loss: 0.0338 - acc: 0.9893\u001b[0m\n",
      "\u001b[31m60000/60000 [==============================] - 1s 20us/step - loss: 0.0337 - acc: 0.9893 - val_loss: 0.0281 - val_acc: 0.9912\u001b[0m\n",
      "\u001b[31mEpoch 10/10\n",
      "\n",
      "  256/60000 [..............................] - ETA: 1s - loss: 0.0362 - acc: 0.9922\n",
      " 3072/60000 [>.............................] - ETA: 1s - loss: 0.0259 - acc: 0.9912\n",
      " 5888/60000 [=>............................] - ETA: 1s - loss: 0.0280 - acc: 0.9908\n",
      " 8704/60000 [===>..........................] - ETA: 0s - loss: 0.0275 - acc: 0.9908\u001b[0m\n",
      "\u001b[31m11520/60000 [====>.........................] - ETA: 0s - loss: 0.0273 - acc: 0.9906\u001b[0m\n",
      "\u001b[31m14336/60000 [======>.......................] - ETA: 0s - loss: 0.0266 - acc: 0.9912\u001b[0m\n",
      "\u001b[31m17152/60000 [=======>......................] - ETA: 0s - loss: 0.0263 - acc: 0.9914\u001b[0m\n",
      "\u001b[31m19968/60000 [========>.....................] - ETA: 0s - loss: 0.0282 - acc: 0.9910\u001b[0m\n",
      "\u001b[31m22784/60000 [==========>...................] - ETA: 0s - loss: 0.0294 - acc: 0.9910\u001b[0m\n",
      "\u001b[31m25600/60000 [===========>..................] - ETA: 0s - loss: 0.0293 - acc: 0.9910\u001b[0m\n",
      "\u001b[31m28416/60000 [=============>................] - ETA: 0s - loss: 0.0297 - acc: 0.9910\u001b[0m\n",
      "\u001b[31m31232/60000 [==============>...............] - ETA: 0s - loss: 0.0301 - acc: 0.9910\u001b[0m\n",
      "\u001b[31m34048/60000 [================>.............] - ETA: 0s - loss: 0.0307 - acc: 0.9907\u001b[0m\n",
      "\u001b[31m36864/60000 [=================>............] - ETA: 0s - loss: 0.0306 - acc: 0.9906\u001b[0m\n",
      "\u001b[31m39680/60000 [==================>...........] - ETA: 0s - loss: 0.0300 - acc: 0.9908\u001b[0m\n",
      "\u001b[31m42496/60000 [====================>.........] - ETA: 0s - loss: 0.0306 - acc: 0.9907\u001b[0m\n",
      "\u001b[31m45312/60000 [=====================>........] - ETA: 0s - loss: 0.0299 - acc: 0.9908\u001b[0m\n",
      "\u001b[31m48128/60000 [=======================>......] - ETA: 0s - loss: 0.0301 - acc: 0.9907\u001b[0m\n",
      "\u001b[31m50944/60000 [========================>.....] - ETA: 0s - loss: 0.0302 - acc: 0.9906\u001b[0m\n",
      "\u001b[31m53760/60000 [=========================>....] - ETA: 0s - loss: 0.0307 - acc: 0.9905\u001b[0m\n",
      "\u001b[31m56576/60000 [===========================>..] - ETA: 0s - loss: 0.0308 - acc: 0.9905\u001b[0m\n",
      "\u001b[31m59392/60000 [============================>.] - ETA: 0s - loss: 0.0308 - acc: 0.9905\u001b[0m\n",
      "\u001b[31m60000/60000 [==============================] - 1s 20us/step - loss: 0.0308 - acc: 0.9904 - val_loss: 0.0277 - val_acc: 0.9913\u001b[0m\n",
      "\u001b[31mTest loss: 0.027729666373973942\u001b[0m\n",
      "\u001b[31mTest accuracy: 0.9913\u001b[0m\n",
      "\u001b[31mMXNet Backend: Successfully exported the model as MXNet model!\u001b[0m\n",
      "\u001b[31mMXNet symbol file -  /opt/ml/model/model-symbol.json\u001b[0m\n",
      "\u001b[31mMXNet params file -  /opt/ml/model/model-0000.params\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[31mModel input data_names and data_shapes are: \u001b[0m\n",
      "\u001b[31mdata_names :  ['/conv2d_1_input1']\u001b[0m\n",
      "\u001b[31mdata_shapes :  [DataDesc[/conv2d_1_input1,(256, 1, 28, 28),float32,NCHW]]\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[31mNote: In the above data_shapes, the first dimension represent the batch_size used for model training. \u001b[0m\n",
      "\u001b[31mYou can change the batch_size for binding the module based on your inference batch_size.\u001b[0m\n",
      "\u001b[31mSaved MXNet model\u001b[0m\n",
      "Billable seconds: 94\n"
     ]
    }
   ],
   "source": [
    "output_path = 's3://{}/{}/output'.format(sess.default_bucket(), repo_name)\n",
    "image_name  = '{}.dkr.ecr.{}.amazonaws.com/{}:latest'.format(account, region, repo_name)\n",
    "\n",
    "print(output_path)\n",
    "print(image_name)\n",
    "\n",
    "estimator = sagemaker.estimator.Estimator(\n",
    "                       image_name=image_name,\n",
    "                       base_job_name=base_job_name,\n",
    "                       role=role, \n",
    "                       train_instance_count=1, \n",
    "                       train_instance_type=train_instance_type,\n",
    "                       output_path=output_path,\n",
    "                       sagemaker_session=sess)\n",
    "\n",
    "estimator.set_hyperparameters(lr=0.01, epochs=10, gpus=gpu_count, batch_size=batch_size)\n",
    "\n",
    "estimator.fit({'training': train_input_path, 'validation': validation_input_path})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path=output_path+'/keras-mxnet-mnist-cnn-2019-03-13-00-10-16-492/output/model.tar.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws cp model_path ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.mxnet import MXNet, MXNetModel\n",
    "\n",
    "sagemaker_model = MXNetModel(model_data = model_path,\n",
    "                             role = role,\n",
    "                             entry_point = 'default_classifier.py',\n",
    "                             py_version='py3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating model with name: sagemaker-mxnet-2019-03-13-00-18-47-286\n",
      "INFO:sagemaker:Creating endpoint with name sagemaker-mxnet-2019-03-13-00-18-47-286\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------------------------------------------------*"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Error hosting endpoint sagemaker-mxnet-2019-03-13-00-18-47-286: Failed Reason:  The primary container for production variant AllTraffic did not pass the ping health check. Please check CloudWatch logs for this endpoint.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-108-85358186ad84>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpredictor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msagemaker_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeploy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minitial_instance_count\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minstance_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ml.m4.xlarge'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/sagemaker/model.py\u001b[0m in \u001b[0;36mdeploy\u001b[0;34m(self, initial_instance_count, instance_type, accelerator_type, endpoint_name, update_endpoint, tags)\u001b[0m\n\u001b[1;32m    260\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_endpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendpoint_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mendpoint_config_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendpoint_from_production_variants\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendpoint_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mproduction_variant\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredictor_cls\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/sagemaker/session.py\u001b[0m in \u001b[0;36mendpoint_from_production_variants\u001b[0;34m(self, name, production_variants, tags, wait)\u001b[0m\n\u001b[1;32m   1015\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_endpoint_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mconfig_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1017\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_endpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mendpoint_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1018\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1019\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mexpand_role\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrole\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/sagemaker/session.py\u001b[0m in \u001b[0;36mcreate_endpoint\u001b[0;34m(self, endpoint_name, config_name, wait)\u001b[0m\n\u001b[1;32m    748\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_endpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEndpointName\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mendpoint_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEndpointConfigName\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    749\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 750\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait_for_endpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mendpoint_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    751\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mendpoint_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    752\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/sagemaker/session.py\u001b[0m in \u001b[0;36mwait_for_endpoint\u001b[0;34m(self, endpoint, poll)\u001b[0m\n\u001b[1;32m    885\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstatus\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'InService'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    886\u001b[0m             \u001b[0mreason\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'FailureReason'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 887\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Error hosting endpoint {}: {} Reason: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mendpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreason\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    888\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    889\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error hosting endpoint sagemaker-mxnet-2019-03-13-00-18-47-286: Failed Reason:  The primary container for production variant AllTraffic did not pass the ping health check. Please check CloudWatch logs for this endpoint."
     ]
    }
   ],
   "source": [
    "predictor = sagemaker_model.deploy(initial_instance_count=1, instance_type='ml.m4.xlarge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_mxnet_p36",
   "language": "python",
   "name": "conda_mxnet_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
