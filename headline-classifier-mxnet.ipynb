{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End-to-end NLP: News Headline classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup execution role and session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "4c1a412b-4535-46d5-8fe3-e8600801817a",
    "_uuid": "4e6801037e5274668f0b8667591d41c1abbe8be1"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "role = get_execution_role()\n",
    "print(role)\n",
    "sess = sagemaker.Session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download News Aggregator Dataset available at the public UCI dataset repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2019-03-12 22:53:26--  https://archive.ics.uci.edu/ml/machine-learning-databases/00359/NewsAggregatorDataset.zip\n",
      "Resolving archive.ics.uci.edu (archive.ics.uci.edu)... 128.195.10.249\n",
      "Connecting to archive.ics.uci.edu (archive.ics.uci.edu)|128.195.10.249|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 29224203 (28M) [application/zip]\n",
      "Saving to: ‘NewsAggregatorDataset.zip’\n",
      "\n",
      "NewsAggregatorDatas 100%[===================>]  27.87M  6.59MB/s    in 11s     \n",
      "\n",
      "2019-03-12 22:53:40 (2.43 MB/s) - ‘NewsAggregatorDataset.zip’ saved [29224203/29224203]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://archive.ics.uci.edu/ml/machine-learning-databases/00359/NewsAggregatorDataset.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  NewsAggregatorDataset.zip\n",
      "  inflating: 2pageSessions.csv       \n",
      "   creating: __MACOSX/\n",
      "  inflating: __MACOSX/._2pageSessions.csv  \n",
      "  inflating: newsCorpora.csv         \n",
      "  inflating: __MACOSX/._newsCorpora.csv  \n",
      "  inflating: readme.txt              \n",
      "  inflating: __MACOSX/._readme.txt   \n"
     ]
    }
   ],
   "source": [
    "!unzip NewsAggregatorDataset.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf __MACOSX/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's visualize the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import mxnet\n",
    "import re\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TITLE</th>\n",
       "      <th>URL</th>\n",
       "      <th>PUBLISHER</th>\n",
       "      <th>CATEGORY</th>\n",
       "      <th>STORY</th>\n",
       "      <th>HOSTNAME</th>\n",
       "      <th>TIMESTAMP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fed official says weak data caused by weather,...</td>\n",
       "      <td>http://www.latimes.com/business/money/la-fi-mo...</td>\n",
       "      <td>Los Angeles Times</td>\n",
       "      <td>b</td>\n",
       "      <td>ddUyU0VZz0BRneMioxUPQVP6sIxvM</td>\n",
       "      <td>www.latimes.com</td>\n",
       "      <td>1394470370698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fed's Charles Plosser sees high bar for change...</td>\n",
       "      <td>http://www.livemint.com/Politics/H2EvwJSK2VE6O...</td>\n",
       "      <td>Livemint</td>\n",
       "      <td>b</td>\n",
       "      <td>ddUyU0VZz0BRneMioxUPQVP6sIxvM</td>\n",
       "      <td>www.livemint.com</td>\n",
       "      <td>1394470371207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>US open: Stocks fall after Fed official hints ...</td>\n",
       "      <td>http://www.ifamagazine.com/news/us-open-stocks...</td>\n",
       "      <td>IFA Magazine</td>\n",
       "      <td>b</td>\n",
       "      <td>ddUyU0VZz0BRneMioxUPQVP6sIxvM</td>\n",
       "      <td>www.ifamagazine.com</td>\n",
       "      <td>1394470371550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fed risks falling 'behind the curve', Charles ...</td>\n",
       "      <td>http://www.ifamagazine.com/news/fed-risks-fall...</td>\n",
       "      <td>IFA Magazine</td>\n",
       "      <td>b</td>\n",
       "      <td>ddUyU0VZz0BRneMioxUPQVP6sIxvM</td>\n",
       "      <td>www.ifamagazine.com</td>\n",
       "      <td>1394470371793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Fed's Plosser: Nasty Weather Has Curbed Job Gr...</td>\n",
       "      <td>http://www.moneynews.com/Economy/federal-reser...</td>\n",
       "      <td>Moneynews</td>\n",
       "      <td>b</td>\n",
       "      <td>ddUyU0VZz0BRneMioxUPQVP6sIxvM</td>\n",
       "      <td>www.moneynews.com</td>\n",
       "      <td>1394470372027</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               TITLE  \\\n",
       "1  Fed official says weak data caused by weather,...   \n",
       "2  Fed's Charles Plosser sees high bar for change...   \n",
       "3  US open: Stocks fall after Fed official hints ...   \n",
       "4  Fed risks falling 'behind the curve', Charles ...   \n",
       "5  Fed's Plosser: Nasty Weather Has Curbed Job Gr...   \n",
       "\n",
       "                                                 URL          PUBLISHER  \\\n",
       "1  http://www.latimes.com/business/money/la-fi-mo...  Los Angeles Times   \n",
       "2  http://www.livemint.com/Politics/H2EvwJSK2VE6O...           Livemint   \n",
       "3  http://www.ifamagazine.com/news/us-open-stocks...       IFA Magazine   \n",
       "4  http://www.ifamagazine.com/news/fed-risks-fall...       IFA Magazine   \n",
       "5  http://www.moneynews.com/Economy/federal-reser...          Moneynews   \n",
       "\n",
       "  CATEGORY                          STORY             HOSTNAME      TIMESTAMP  \n",
       "1        b  ddUyU0VZz0BRneMioxUPQVP6sIxvM      www.latimes.com  1394470370698  \n",
       "2        b  ddUyU0VZz0BRneMioxUPQVP6sIxvM     www.livemint.com  1394470371207  \n",
       "3        b  ddUyU0VZz0BRneMioxUPQVP6sIxvM  www.ifamagazine.com  1394470371550  \n",
       "4        b  ddUyU0VZz0BRneMioxUPQVP6sIxvM  www.ifamagazine.com  1394470371793  \n",
       "5        b  ddUyU0VZz0BRneMioxUPQVP6sIxvM    www.moneynews.com  1394470372027  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column_names = [\"TITLE\", \"URL\", \"PUBLISHER\", \"CATEGORY\", \"STORY\", \"HOSTNAME\", \"TIMESTAMP\"]\n",
    "news_dataset = pd.read_csv('newsCorpora.csv', names=column_names, header=None, delimiter='\\t')\n",
    "news_dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For this exercice we'll only use the title (Headline) of the news story and the category as our target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=news_dataset[['TITLE',\"CATEGORY\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'b': 115967, 't': 108344, 'e': 152469, 'm': 45639})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "Counter(df['CATEGORY'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset has four categories: Business (b), Science & Technology (t), Entertainment (e) and Health & Medicine (m)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dummy encode the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using MXNet backend\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "from keras.utils.np_utils import to_categorical\n",
    "encoder = preprocessing.LabelEncoder()\n",
    "\n",
    "docs = df[\"TITLE\"].values\n",
    "\n",
    "encoder.fit(df[\"CATEGORY\"].values)\n",
    "encoded_Y = encoder.transform(df[\"CATEGORY\"].values)\n",
    "# convert integers to dummy variables (i.e. one hot encoded)\n",
    "dummy_y = to_categorical(encoded_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bucket = <bucket> # custom bucket name.\n",
    "s3_bucket = sess.default_bucket()\n",
    "s3_prefix = 'news'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['b', 'e', 'm', 't']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(encoder.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 2, 2, 2])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tokenize documents and set fixed sequence lengths for input feature dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "_cell_guid": "7bcf422f-0e75-4d49-b3b1-12553fcaf4ff",
    "_uuid": "46b7fc9aef5a519f96a295e980ba15deee781e97",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75286\n",
      "422419\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# prepare tokenizer\n",
    "t = Tokenizer()\n",
    "t.fit_on_texts(docs)\n",
    "vocab_size = len(t.word_index) + 1\n",
    "# integer encode the documents\n",
    "encoded_docs = t.texts_to_sequences(docs)\n",
    "print(vocab_size)\n",
    "# pad documents to a max length of 4 words\n",
    "max_length = 40\n",
    "padded_docs = pad_sequences(encoded_docs, maxlen=max_length, padding='post')\n",
    "print(len(padded_docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Fed official says weak data caused by weather, should not slow taper'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import word embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2019-03-12 22:54:25--  http://nlp.stanford.edu/data/glove.6B.zip\n",
      "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
      "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
      "--2019-03-12 22:54:25--  https://nlp.stanford.edu/data/glove.6B.zip\n",
      "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 862182613 (822M) [application/zip]\n",
      "Saving to: ‘glove.6B.zip’\n",
      "\n",
      "glove.6B.zip        100%[===================>] 822.24M  5.53MB/s    in 2m 52s  \n",
      "\n",
      "2019-03-12 22:57:18 (4.79 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n",
      "\n",
      "Archive:  glove.6B.zip\n",
      "  inflating: glove.6B.50d.txt        \n",
      "  inflating: glove.6B.100d.txt       \n",
      "  inflating: glove.6B.200d.txt       \n",
      "  inflating: glove.6B.300d.txt       \n"
     ]
    }
   ],
   "source": [
    "!wget http://nlp.stanford.edu/data/glove.6B.zip && unzip glove.6B.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "rm 2pageSessions.csv glove.6B.200d.txt glove.6B.50d.txt glove.6B.300d.txt glove.6B.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Create embedding matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "_cell_guid": "9182c6ea-cd7d-46a1-bd29-a532e0935474",
    "_uuid": "31ef8ec3a8d8a6229dc767a90061dfc50294b456"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "# load the whole embedding into memory\n",
    "embeddings_index = dict()\n",
    "f = open('glove.6B.100d.txt')\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "print('Loaded %s word vectors.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './vectors.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-21dab71000da>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# load the whole embedding into memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0membeddings_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./vectors.txt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './vectors.txt'"
     ]
    }
   ],
   "source": [
    "# load the whole embedding into memory\n",
    "embeddings_index = dict()\n",
    "f = open('./vectors.txt')\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "print('Loaded %s word vectors.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "#embeddings_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "_cell_guid": "97ec3b51-53be-4078-a72a-a4222d2ffac0",
    "_uuid": "72b42e2a27337810e4604db0f67d626a62008854"
   },
   "outputs": [],
   "source": [
    "#print(t.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "_cell_guid": "fa875535-7cef-40da-9add-dfe1d51395b0",
    "_uuid": "befd8941982ee2119daa0b9cc6b10a1e14656239"
   },
   "outputs": [],
   "source": [
    "# create a weight matrix for words in training docs\n",
    "embedding_matrix = np.zeros((vocab_size, 100))\n",
    "for word, i in t.word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "mkdir ./data/embeddings/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "_cell_guid": "593bfd0a-b703-4e87-96dd-a7eb98e6940e",
    "_uuid": "f71c5f0b731d3418d3cb83be758233b5030da29d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(75286, 100)\n"
     ]
    }
   ],
   "source": [
    "#embedding_matrix.dump(\"ingredients-embedding-matrix.dat\")\n",
    "np.save(file=\"./data/embeddings/docs-embedding-matrix\",\n",
    "        arr=embedding_matrix,\n",
    "        allow_pickle=False)\n",
    "print(embedding_matrix.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train, test split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we will prep the data for ingestion for the algortihm. Split the data set in train and test samples and uplad the data to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(padded_docs, dummy_y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘data/embeddings/’: File exists\r\n"
     ]
    }
   ],
   "source": [
    "!mkdir data/train/ data/test/ data/embeddings/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('./data/train/train_X.npy', X_train)\n",
    "np.save('./data/train/train_Y.npy', y_train)\n",
    "np.save('./data/test/test_X.npy', X_test)\n",
    "np.save('./data/test/test_Y.npy', y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindata_s3_prefix = '{}/data/train'.format(s3_prefix)\n",
    "testdata_s3_prefix = '{}/data/test'.format(s3_prefix)\n",
    "embeddings_s3_prefix='{}/data/embeddings'.format(s3_prefix)\n",
    "output_s3 = 's3://{}/{}/models/'.format(s3_bucket, s3_prefix)\n",
    "code_location_s3 = 's3://{}/{}/codes'.format(s3_bucket, s3_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_s3 = sess.upload_data(path='./data/train/', bucket=s3_bucket, key_prefix=traindata_s3_prefix)\n",
    "test_s3 = sess.upload_data(path='./data/test/', bucket=s3_bucket, key_prefix=testdata_s3_prefix)\n",
    "embeddings_s3 = sess.upload_data(path='./data/embeddings/', bucket=s3_bucket, key_prefix=embeddings_s3_prefix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train': 's3://sagemaker-ap-southeast-1-349934754982/news/data/train', 'test': 's3://sagemaker-ap-southeast-1-349934754982/news/data/test', 'embeddings': 's3://sagemaker-ap-southeast-1-349934754982/news/data/embeddings'}\n"
     ]
    }
   ],
   "source": [
    "inputs = {'train':train_s3, 'test': test_s3, 'embeddings': embeddings_s3}\n",
    "\n",
    "print(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker.mxnet import MXNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define hyperparameters to push to algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = {'epochs': 5, 'vocab_size':vocab_size, 'num_classes':encoder.classes_.size}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: sagemaker-mxnet-2019-03-13-00-52-10-529\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-03-13 00:52:12 Starting - Starting the training job...\n",
      "2019-03-13 00:52:14 Starting - Launching requested ML instances......\n",
      "2019-03-13 00:53:18 Starting - Preparing the instances for training......\n",
      "2019-03-13 00:54:30 Downloading - Downloading input data\n",
      "2019-03-13 00:54:30 Training - Downloading the training image...\n",
      "2019-03-13 00:54:56 Training - Training image download completed. Training in progress.\n",
      "\u001b[31m2019-03-13 00:54:57,349 sagemaker-containers INFO     Imported framework sagemaker_mxnet_container.training\u001b[0m\n",
      "\u001b[31m2019-03-13 00:54:57,396 sagemaker_mxnet_container.training INFO     MXNet training environment: {'SM_TRAINING_ENV': '{\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"embeddings\":\"/opt/ml/input/data/embeddings\",\"test\":\"/opt/ml/input/data/test\",\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_mxnet_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"epochs\":5,\"num_classes\":4,\"vocab_size\":75286},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"embeddings\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"test\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"sagemaker-mxnet-2019-03-13-00-52-10-529\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-ap-southeast-1-349934754982/sagemaker-mxnet-2019-03-13-00-52-10-529/source/sourcedir.tar.gz\",\"module_name\":\"keras_script_mxnet\",\"network_interface_name\":\"ethwe\",\"num_cpus\":32,\"num_gpus\":4,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"ethwe\"},\"user_entry_point\":\"keras_script_mxnet.py\"}', 'SM_USER_ENTRY_POINT': 'keras_script_mxnet.py', 'SM_FRAMEWORK_MODULE': 'sagemaker_mxnet_container.training:main', 'SM_NUM_GPUS': '4', 'SM_OUTPUT_DATA_DIR': '/opt/ml/output/data', 'SM_RESOURCE_CONFIG': '{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"ethwe\"}', 'SM_CHANNEL_TRAIN': '/opt/ml/input/data/train', 'SM_INPUT_DIR': '/opt/ml/input', 'SM_OUTPUT_INTERMEDIATE_DIR': '/opt/ml/output/intermediate', 'SM_INPUT_CONFIG_DIR': '/opt/ml/input/config', 'SM_HP_EPOCHS': '5', 'SM_CHANNELS': '[\"embeddings\u001b[0m\n",
      "\u001b[31m2019-03-13 00:54:57,668 sagemaker-containers INFO     Module keras_script_mxnet does not provide a setup.py. \u001b[0m\n",
      "\u001b[31mGenerating setup.py\u001b[0m\n",
      "\u001b[31m2019-03-13 00:54:57,668 sagemaker-containers INFO     Generating setup.cfg\u001b[0m\n",
      "\u001b[31m2019-03-13 00:54:57,668 sagemaker-containers INFO     Generating MANIFEST.in\u001b[0m\n",
      "\u001b[31m2019-03-13 00:54:57,669 sagemaker-containers INFO     Installing module with the following command:\u001b[0m\n",
      "\u001b[31m/usr/bin/python -m pip install -U . \u001b[0m\n",
      "\u001b[31mProcessing /opt/ml/code\u001b[0m\n",
      "\u001b[31mBuilding wheels for collected packages: keras-script-mxnet\n",
      "  Running setup.py bdist_wheel for keras-script-mxnet: started\n",
      "  Running setup.py bdist_wheel for keras-script-mxnet: finished with status 'done'\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-9gehbz6k/wheels/35/24/16/37574d11bf9bde50616c67372a334f94fa8356bc7164af8ca3\u001b[0m\n",
      "\u001b[31mSuccessfully built keras-script-mxnet\u001b[0m\n",
      "\u001b[31mInstalling collected packages: keras-script-mxnet\u001b[0m\n",
      "\u001b[31mSuccessfully installed keras-script-mxnet-1.0.0\u001b[0m\n",
      "\u001b[31mYou are using pip version 18.1, however version 19.0.3 is available.\u001b[0m\n",
      "\u001b[31mYou should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "\u001b[31m2019-03-13 00:54:59,155 sagemaker-containers INFO     Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[31mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[31m{\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"framework_module\": \"sagemaker_mxnet_container.training:main\",\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"log_level\": 20,\n",
      "    \"hyperparameters\": {\n",
      "        \"num_classes\": 4,\n",
      "        \"epochs\": 5,\n",
      "        \"vocab_size\": 75286\n",
      "    },\n",
      "    \"num_gpus\": 4,\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"input_data_config\": {\n",
      "        \"test\": {\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\",\n",
      "            \"TrainingInputMode\": \"File\"\n",
      "        },\n",
      "        \"embeddings\": {\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\",\n",
      "            \"TrainingInputMode\": \"File\"\n",
      "        },\n",
      "        \"train\": {\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\",\n",
      "            \"TrainingInputMode\": \"File\"\n",
      "        }\n",
      "    },\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"job_name\": \"sagemaker-mxnet-2019-03-13-00-52-10-529\",\n",
      "    \"num_cpus\": 32,\n",
      "    \"module_dir\": \"s3://sagemaker-ap-southeast-1-349934754982/sagemaker-mxnet-2019-03-13-00-52-10-529/source/sourcedir.tar.gz\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"network_interface_name\": \"ethwe\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"network_interface_name\": \"ethwe\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ]\n",
      "    },\n",
      "    \"channel_input_dirs\": {\n",
      "        \"test\": \"/opt/ml/input/data/test\",\n",
      "        \"embeddings\": \"/opt/ml/input/data/embeddings\",\n",
      "        \"train\": \"/opt/ml/input/data/train\"\n",
      "    },\n",
      "    \"is_master\": true,\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"module_name\": \"keras_script_mxnet\",\n",
      "    \"user_entry_point\": \"keras_script_mxnet.py\"\u001b[0m\n",
      "\u001b[31m}\n",
      "\u001b[0m\n",
      "\u001b[31mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[31mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"embeddings\":\"/opt/ml/input/data/embeddings\",\"test\":\"/opt/ml/input/data/test\",\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_mxnet_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"epochs\":5,\"num_classes\":4,\"vocab_size\":75286},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"embeddings\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"test\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"sagemaker-mxnet-2019-03-13-00-52-10-529\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-ap-southeast-1-349934754982/sagemaker-mxnet-2019-03-13-00-52-10-529/source/sourcedir.tar.gz\",\"module_name\":\"keras_script_mxnet\",\"network_interface_name\":\"ethwe\",\"num_cpus\":32,\"num_gpus\":4,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"ethwe\"},\"user_entry_point\":\"keras_script_mxnet.py\"}\u001b[0m\n",
      "\u001b[31mSM_INPUT_DATA_CONFIG={\"embeddings\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"test\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[31mSM_NUM_CPUS=32\u001b[0m\n",
      "\u001b[31mSM_FRAMEWORK_MODULE=sagemaker_mxnet_container.training:main\u001b[0m\n",
      "\u001b[31mSM_NUM_GPUS=4\u001b[0m\n",
      "\u001b[31mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[31mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[31mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"ethwe\"}\u001b[0m\n",
      "\u001b[31mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001b[0m\n",
      "\u001b[31mPYTHONPATH=/usr/local/bin:/usr/lib/python35.zip:/usr/lib/python3.5:/usr/lib/python3.5/plat-x86_64-linux-gnu:/usr/lib/python3.5/lib-dynload:/usr/local/lib/python3.5/dist-packages:/usr/lib/python3/dist-packages\u001b[0m\n",
      "\u001b[31mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[31mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[31mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[31mSM_HP_EPOCHS=5\u001b[0m\n",
      "\u001b[31mSM_CHANNELS=[\"embeddings\",\"test\",\"train\"]\u001b[0m\n",
      "\u001b[31mSM_NETWORK_INTERFACE_NAME=ethwe\u001b[0m\n",
      "\u001b[31mSM_USER_ENTRY_POINT=keras_script_mxnet.py\u001b[0m\n",
      "\u001b[31mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[31mSM_HP_NUM_CLASSES=4\u001b[0m\n",
      "\u001b[31mSM_CHANNEL_EMBEDDINGS=/opt/ml/input/data/embeddings\u001b[0m\n",
      "\u001b[31mSM_HPS={\"epochs\":5,\"num_classes\":4,\"vocab_size\":75286}\u001b[0m\n",
      "\u001b[31mSM_MODULE_DIR=s3://sagemaker-ap-southeast-1-349934754982/sagemaker-mxnet-2019-03-13-00-52-10-529/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[31mSM_MODULE_NAME=keras_script_mxnet\u001b[0m\n",
      "\u001b[31mSM_HP_VOCAB_SIZE=75286\u001b[0m\n",
      "\u001b[31mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[31mSM_CHANNEL_TEST=/opt/ml/input/data/test\u001b[0m\n",
      "\u001b[31mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[31mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[31mSM_USER_ARGS=[\"--epochs\",\"5\",\"--num_classes\",\"4\",\"--vocab_size\",\"75286\"]\u001b[0m\n",
      "\u001b[31mSM_HOSTS=[\"algo-1\"]\n",
      "\u001b[0m\n",
      "\u001b[31mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[31m/usr/bin/python -m keras_script_mxnet --epochs 5 --num_classes 4 --vocab_size 75286\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[31mUsing MXNet backend\u001b[0m\n",
      "\u001b[31mNamespace(embeddings='/opt/ml/input/data/embeddings', epochs=5, model_dir='/opt/ml/model', num_classes=4, output_data_dir='/opt/ml/output/data', test='/opt/ml/input/data/test', train='/opt/ml/input/data/train', vocab_size=75286)\u001b[0m\n",
      "\u001b[31m/usr/local/lib/python3.5/dist-packages/keras/backend/mxnet_backend.py:89: UserWarning: MXNet Backend performs best with `channels_first` format. Using `channels_last` will significantly reduce performance due to the Transpose operations. For performance improvement, please use this API`keras.utils.to_channels_first(x_input)`to transform `channels_last` data to `channels_first` format and also please change the `image_data_format` in `keras.json` to `channels_first`.Note: `x_input` is a Numpy tensor or a list of Numpy tensorRefer to: https://github.com/awslabs/keras-apache-mxnet/tree/master/docs/mxnet_backend/performance_guide.md\n",
      "  train_symbol = func(*args, **kwargs)\u001b[0m\n",
      "\u001b[31m/usr/local/lib/python3.5/dist-packages/keras/backend/mxnet_backend.py:92: UserWarning: MXNet Backend performs best with `channels_first` format. Using `channels_last` will significantly reduce performance due to the Transpose operations. For performance improvement, please use this API`keras.utils.to_channels_first(x_input)`to transform `channels_last` data to `channels_first` format and also please change the `image_data_format` in `keras.json` to `channels_first`.Note: `x_input` is a Numpy tensor or a list of Numpy tensorRefer to: https://github.com/awslabs/keras-apache-mxnet/tree/master/docs/mxnet_backend/performance_guide.md\n",
      "  test_symbol = func(*args, **kwargs)\u001b[0m\n",
      "\u001b[31m_________________________________________________________________\u001b[0m\n",
      "\u001b[31mLayer (type)                 Output Shape              Param #   \u001b[0m\n",
      "\u001b[31m=================================================================\u001b[0m\n",
      "\u001b[31membed (Embedding)            (None, 40, 100)           7528600   \u001b[0m\n",
      "\u001b[31m_________________________________________________________________\u001b[0m\n",
      "\u001b[31mconv_1 (Conv1D)              (None, 38, 128)           38528     \u001b[0m\n",
      "\u001b[31m_________________________________________________________________\u001b[0m\n",
      "\u001b[31mmaxpool_1 (MaxPooling1D)     (None, 7, 128)            0         \u001b[0m\n",
      "\u001b[31m_________________________________________________________________\u001b[0m\n",
      "\u001b[31mflat_1 (Flatten)             (None, 896)               0         \u001b[0m\n",
      "\u001b[31m_________________________________________________________________\u001b[0m\n",
      "\u001b[31mdropout_1 (Dropout)          (None, 896)               0         \u001b[0m\n",
      "\u001b[31m_________________________________________________________________\u001b[0m\n",
      "\u001b[31mdense_1 (Dense)              (None, 128)               114816    \u001b[0m\n",
      "\u001b[31m_________________________________________________________________\u001b[0m\n",
      "\u001b[31mout_1 (Dense)                (None, 4)                 516       \u001b[0m\n",
      "\u001b[31m=================================================================\u001b[0m\n",
      "\u001b[31mTotal params: 7,682,460\u001b[0m\n",
      "\u001b[31mTrainable params: 153,860\u001b[0m\n",
      "\u001b[31mNon-trainable params: 7,528,600\u001b[0m\n",
      "\u001b[31m_________________________________________________________________\u001b[0m\n",
      "\u001b[31mEpoch 1/5\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m/usr/local/lib/python3.5/dist-packages/mxnet/module/bucketing_module.py:408: UserWarning: Optimizer created manually outside Module but rescale_grad is not normalized to 1.0/batch_size/num_workers (1.0 vs. 0.0625). Is this intended?\n",
      "  force_init=force_init)\u001b[0m\n",
      "\u001b[31m[00:55:10] src/operator/nn/./cudnn/./cudnn_algoreg-inl.h:109: Running performance tests to find the best convolution algorithm, this can take a while... (setting env variable MXNET_CUDNN_AUTOTUNE_DEFAULT to 0 to disable)\u001b[0m\n",
      "\u001b[31m - 57s - loss: 0.5388 - acc: 0.7500\u001b[0m\n",
      "\u001b[31mEpoch 2/5\u001b[0m\n",
      "\u001b[31m - 48s - loss: 0.5384 - acc: 0.7500\u001b[0m\n",
      "\u001b[31mEpoch 3/5\u001b[0m\n",
      "\u001b[31m - 48s - loss: 0.5384 - acc: 0.7500\u001b[0m\n",
      "\u001b[31mEpoch 4/5\u001b[0m\n",
      "\u001b[31m - 48s - loss: 0.5384 - acc: 0.7500\u001b[0m\n",
      "\u001b[31mEpoch 5/5\u001b[0m\n",
      "\u001b[31m - 48s - loss: 0.5384 - acc: 0.7500\u001b[0m\n",
      "\u001b[31m[00:59:10] src/executor/../common/exec_utils.h:475: Bucketing: data /out_1_target1 has a shape [32,4], which is larger than already allocated shape [16,4]. Need to re-allocate. Consider putting default bucket key to be the bucket taking the largest input for better memory sharing.\u001b[0m\n",
      "\u001b[31m[00:59:10] src/executor/../common/exec_utils.h:475: Bucketing: data /embed_input1 has a shape [32,40], which is larger than already allocated shape [16,40]. Need to re-allocate. Consider putting default bucket key to be the bucket taking the largest input for better memory sharing.\u001b[0m\n",
      "\u001b[31m[00:59:10] src/executor/../common/exec_utils.h:475: Bucketing: data /out_1_sample_weights1 has a shape [32], which is larger than already allocated shape [16]. Need to re-allocate. Consider putting default bucket key to be the bucket taking the largest input for better memory sharing.\u001b[0m\n",
      "\u001b[31mMXNet Backend: Successfully exported the model as MXNet model!\u001b[0m\n",
      "\u001b[31mMXNet symbol file -  /opt/ml/model/model-symbol.json\u001b[0m\n",
      "\u001b[31mMXNet params file -  /opt/ml/model/model-0000.params\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[31mModel input data_names and data_shapes are: \u001b[0m\n",
      "\u001b[31mdata_names :  ['/embed_input1']\u001b[0m\n",
      "\u001b[31mdata_shapes :  [DataDesc[/embed_input1,(16, 40),float32,NCHW]]\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[31mNote: In the above data_shapes, the first dimension represent the batch_size used for model training. \u001b[0m\n",
      "\u001b[31mYou can change the batch_size for binding the module based on your inference batch_size.\u001b[0m\n",
      "\u001b[31m2019-03-13 00:59:15,494 sagemaker-containers INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2019-03-13 01:00:04 Uploading - Uploading generated training model\n",
      "2019-03-13 01:00:04 Completed - Training job completed\n",
      "Billable seconds: 343\n"
     ]
    }
   ],
   "source": [
    "mxnet_estimator = MXNet(entry_point='keras_script_mxnet.py',\n",
    "                       source_dir='./tf-src',\n",
    "                        role=role,\n",
    "                        train_instance_type='ml.p3.8xlarge',\n",
    "                        train_instance_count=1,\n",
    "                        framework_version='1.3.0',\n",
    "                        py_version='py3',\n",
    "                        hyperparameters=hyperparameters)\n",
    "mxnet_estimator.fit(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "s3 = boto3.resource('s3')\n",
    "\n",
    "key = mxnet_estimator.model_data[mxnet_estimator.model_data.find(\"/\", 5)+1:]\n",
    "s3.Bucket(s3_bucket).download_file(key, 'model.tar.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.mxnet import MXNet, MXNetModel\n",
    "\n",
    "sagemaker_model = MXNetModel(model_data = model_path,\n",
    "                             role = role,\n",
    "                             entry_point = 'default_classifier.py',\n",
    "                             py_version='py3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating model with name: sagemaker-mxnet-2019-03-12-23-46-12-811\n",
      "INFO:sagemaker:Creating endpoint with name sagemaker-mxnet-2019-03-12-23-46-12-811\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------!"
     ]
    }
   ],
   "source": [
    "predictor = mxnet_estimator.deploy(initial_instance_count=1,\n",
    "                           instance_type='ml.m4.xlarge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'application/json'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'text/csv'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<sagemaker.predictor._JsonDeserializer at 0x7fd7c4546f98>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'sagemaker-mxnet-2019-03-12-23-46-12-811'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<sagemaker.session.Session at 0x7fd73da5ab70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<sagemaker.predictor._JsonSerializer at 0x7fd7c4546f28>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(predictor.accept, predictor.content_type, predictor.deserializer, predictor.endpoint, predictor.sagemaker_session, predictor.serializer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predictor.predict(padded_example.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "s3 = boto3.resource('s3')\n",
    "\n",
    "key = mxnet_estimator.model_data[mxnet_estimator.model_data.find(\"/\", 5)+1:]\n",
    "s3.Bucket(s3_bucket).download_file(key, 'model.tar.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model-0000.params\n",
      "model-symbol.json\n",
      "model-shapes.json\n",
      "model.hd5\n"
     ]
    }
   ],
   "source": [
    "!tar -xvzf model.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/keras/backend/mxnet_backend.py:89: UserWarning: MXNet Backend performs best with `channels_first` format. Using `channels_last` will significantly reduce performance due to the Transpose operations. For performance improvement, please use this API`keras.utils.to_channels_first(x_input)`to transform `channels_last` data to `channels_first` format and also please change the `image_data_format` in `keras.json` to `channels_first`.Note: `x_input` is a Numpy tensor or a list of Numpy tensorRefer to: https://github.com/awslabs/keras-apache-mxnet/tree/master/docs/mxnet_backend/performance_guide.md\n",
      "  train_symbol = func(*args, **kwargs)\n",
      "/home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/keras/backend/mxnet_backend.py:92: UserWarning: MXNet Backend performs best with `channels_first` format. Using `channels_last` will significantly reduce performance due to the Transpose operations. For performance improvement, please use this API`keras.utils.to_channels_first(x_input)`to transform `channels_last` data to `channels_first` format and also please change the `image_data_format` in `keras.json` to `channels_first`.Note: `x_input` is a Numpy tensor or a list of Numpy tensorRefer to: https://github.com/awslabs/keras-apache-mxnet/tree/master/docs/mxnet_backend/performance_guide.md\n",
      "  test_symbol = func(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "loaded_model = load_model(\"model.hd5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_doc=['Senate prepares to vote on dueling plans to end shutdown']\n",
    "# integer encode the document\n",
    "encoded_example = t.texts_to_sequences(example_doc)\n",
    "\n",
    "# pad documents to a max length of 4 words\n",
    "max_length = 40\n",
    "padded_example = pad_sequences(encoded_example, maxlen=max_length, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.27366856,  0.36816129,  0.10714847,  0.25102162]], dtype=float32)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model.predict(padded_example)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_mxnet_p36",
   "language": "python",
   "name": "conda_mxnet_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
